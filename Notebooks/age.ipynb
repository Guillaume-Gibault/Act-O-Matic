{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-22T08:47:09.195929Z",
     "start_time": "2025-01-22T08:46:36.806042Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger les données depuis un fichier CSV\n",
    "data = pd.read_csv(r\"C:\\Users\\33658\\PycharmProjects\\Act-O-Matic\\images_acteurs\\acteurs.csv\")\n",
    "\n",
    "# Charger et prétraiter les images\n",
    "def preprocess_data(data):\n",
    "    images, ages = [], []\n",
    "    for i, row in data.iterrows():\n",
    "        img = cv2.imread(row[\"image_path\"])  # Charger l'image\n",
    "        img = cv2.resize(img, (224, 224))   # Redimensionner\n",
    "        img = img / 255.0                   # Normaliser\n",
    "        images.append(img)\n",
    "        ages.append(row[\"age\"])\n",
    "    return np.array(images), np.array(ages)\n",
    "\n",
    "# Prétraiter les données\n",
    "images, ages = preprocess_data(data)\n",
    "\n",
    "# Diviser en ensembles d'entraînement et de validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(images, ages, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir en tenseurs\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32).shuffle(1000)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(32)\n",
    "\n",
    "# Charger le modèle pré-entraîné MobileNetV2\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Ajouter des couches personnalisées\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(1, activation='linear')(x)  # Activation linéaire pour une régression\n",
    "\n",
    "# Construire le modèle\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Geler les couches du modèle pré-entraîné\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"mean_absolute_error\",  # Erreur absolue moyenne pour la régression\n",
    "    metrics=[\"mae\"]  # Suivi de la MAE\n",
    ")\n",
    "\n",
    "# # Afficher le résumé du modèle\n",
    "# model.summary()\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=100  # Ajustez selon vos besoins\n",
    ")\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "model.save(\"age_estimation_model.h5\")\n",
    "print(\"Modèle sauvegardé sous 'age_estimation_model.h5'\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step - loss: 38.9921 - mae: 38.9921 - val_loss: 35.8801 - val_mae: 35.8801\n",
      "Epoch 2/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 235ms/step - loss: 36.3636 - mae: 36.3636 - val_loss: 33.1301 - val_mae: 33.1301\n",
      "Epoch 3/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 233ms/step - loss: 33.2964 - mae: 33.2964 - val_loss: 30.3937 - val_mae: 30.3937\n",
      "Epoch 4/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 224ms/step - loss: 30.6255 - mae: 30.6255 - val_loss: 27.5594 - val_mae: 27.5594\n",
      "Epoch 5/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 226ms/step - loss: 27.6287 - mae: 27.6287 - val_loss: 24.6442 - val_mae: 24.6442\n",
      "Epoch 6/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 230ms/step - loss: 25.3393 - mae: 25.3393 - val_loss: 21.6344 - val_mae: 21.6344\n",
      "Epoch 7/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 253ms/step - loss: 22.9364 - mae: 22.9364 - val_loss: 18.9915 - val_mae: 18.9915\n",
      "Epoch 8/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 237ms/step - loss: 19.8809 - mae: 19.8809 - val_loss: 16.6080 - val_mae: 16.6080\n",
      "Epoch 9/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 249ms/step - loss: 17.5241 - mae: 17.5241 - val_loss: 14.2017 - val_mae: 14.2017\n",
      "Epoch 10/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 233ms/step - loss: 15.4761 - mae: 15.4761 - val_loss: 12.4030 - val_mae: 12.4030\n",
      "Epoch 11/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 236ms/step - loss: 12.9499 - mae: 12.9499 - val_loss: 10.8688 - val_mae: 10.8688\n",
      "Epoch 12/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 231ms/step - loss: 11.4009 - mae: 11.4009 - val_loss: 9.3383 - val_mae: 9.3383\n",
      "Epoch 13/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 236ms/step - loss: 9.8202 - mae: 9.8202 - val_loss: 8.5343 - val_mae: 8.5343\n",
      "Epoch 14/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 238ms/step - loss: 10.2538 - mae: 10.2538 - val_loss: 8.9162 - val_mae: 8.9162\n",
      "Epoch 15/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 238ms/step - loss: 9.7589 - mae: 9.7589 - val_loss: 9.7141 - val_mae: 9.7141\n",
      "Epoch 16/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 252ms/step - loss: 9.7244 - mae: 9.7244 - val_loss: 10.8248 - val_mae: 10.8248\n",
      "Epoch 17/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 237ms/step - loss: 10.9384 - mae: 10.9384 - val_loss: 11.5965 - val_mae: 11.5965\n",
      "Epoch 18/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 237ms/step - loss: 10.2970 - mae: 10.2970 - val_loss: 12.2209 - val_mae: 12.2209\n",
      "Epoch 19/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 235ms/step - loss: 11.0667 - mae: 11.0667 - val_loss: 12.5403 - val_mae: 12.5403\n",
      "Epoch 20/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 242ms/step - loss: 14.5139 - mae: 14.5139 - val_loss: 12.5191 - val_mae: 12.5191\n",
      "Epoch 21/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 233ms/step - loss: 11.8588 - mae: 11.8588 - val_loss: 12.3003 - val_mae: 12.3003\n",
      "Epoch 22/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 242ms/step - loss: 13.1107 - mae: 13.1107 - val_loss: 11.8664 - val_mae: 11.8664\n",
      "Epoch 23/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 235ms/step - loss: 11.4752 - mae: 11.4752 - val_loss: 11.2897 - val_mae: 11.2897\n",
      "Epoch 24/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 259ms/step - loss: 8.3279 - mae: 8.3279 - val_loss: 10.6288 - val_mae: 10.6288\n",
      "Epoch 25/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 240ms/step - loss: 9.5724 - mae: 9.5724 - val_loss: 9.9233 - val_mae: 9.9233\n",
      "Epoch 26/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 241ms/step - loss: 8.7515 - mae: 8.7515 - val_loss: 9.1721 - val_mae: 9.1721\n",
      "Epoch 27/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 235ms/step - loss: 9.4170 - mae: 9.4170 - val_loss: 8.4458 - val_mae: 8.4458\n",
      "Epoch 28/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 240ms/step - loss: 9.1237 - mae: 9.1237 - val_loss: 8.3174 - val_mae: 8.3174\n",
      "Epoch 29/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 237ms/step - loss: 8.6012 - mae: 8.6012 - val_loss: 8.2501 - val_mae: 8.2501\n",
      "Epoch 30/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 239ms/step - loss: 8.1082 - mae: 8.1082 - val_loss: 8.1839 - val_mae: 8.1839\n",
      "Epoch 31/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 236ms/step - loss: 8.1108 - mae: 8.1108 - val_loss: 8.1230 - val_mae: 8.1230\n",
      "Epoch 32/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 238ms/step - loss: 7.7913 - mae: 7.7913 - val_loss: 8.1559 - val_mae: 8.1559\n",
      "Epoch 33/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 250ms/step - loss: 8.3906 - mae: 8.3906 - val_loss: 8.2772 - val_mae: 8.2772\n",
      "Epoch 34/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 243ms/step - loss: 7.5305 - mae: 7.5305 - val_loss: 8.3404 - val_mae: 8.3404\n",
      "Epoch 35/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 237ms/step - loss: 7.6421 - mae: 7.6421 - val_loss: 8.3529 - val_mae: 8.3529\n",
      "Epoch 36/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 238ms/step - loss: 8.6829 - mae: 8.6829 - val_loss: 8.3280 - val_mae: 8.3280\n",
      "Epoch 37/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 240ms/step - loss: 7.3352 - mae: 7.3352 - val_loss: 8.2782 - val_mae: 8.2782\n",
      "Epoch 38/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 241ms/step - loss: 7.3451 - mae: 7.3451 - val_loss: 8.1943 - val_mae: 8.1943\n",
      "Epoch 39/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 240ms/step - loss: 6.8180 - mae: 6.8180 - val_loss: 8.0998 - val_mae: 8.0998\n",
      "Epoch 40/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 236ms/step - loss: 6.6974 - mae: 6.6974 - val_loss: 7.9762 - val_mae: 7.9762\n",
      "Epoch 41/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 253ms/step - loss: 7.4690 - mae: 7.4690 - val_loss: 7.9503 - val_mae: 7.9503\n",
      "Epoch 42/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 244ms/step - loss: 8.0040 - mae: 8.0040 - val_loss: 7.9572 - val_mae: 7.9572\n",
      "Epoch 43/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 242ms/step - loss: 7.0622 - mae: 7.0622 - val_loss: 7.9610 - val_mae: 7.9610\n",
      "Epoch 44/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 238ms/step - loss: 5.4402 - mae: 5.4402 - val_loss: 7.9567 - val_mae: 7.9567\n",
      "Epoch 45/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 240ms/step - loss: 5.8604 - mae: 5.8604 - val_loss: 7.9576 - val_mae: 7.9576\n",
      "Epoch 46/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 250ms/step - loss: 6.3999 - mae: 6.3999 - val_loss: 7.9519 - val_mae: 7.9519\n",
      "Epoch 47/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 240ms/step - loss: 6.1778 - mae: 6.1778 - val_loss: 8.0203 - val_mae: 8.0203\n",
      "Epoch 48/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 242ms/step - loss: 5.5876 - mae: 5.5876 - val_loss: 8.0513 - val_mae: 8.0513\n",
      "Epoch 49/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 244ms/step - loss: 5.9789 - mae: 5.9789 - val_loss: 8.0538 - val_mae: 8.0538\n",
      "Epoch 50/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 287ms/step - loss: 5.6921 - mae: 5.6921 - val_loss: 8.0552 - val_mae: 8.0552\n",
      "Epoch 51/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 242ms/step - loss: 5.8457 - mae: 5.8457 - val_loss: 8.0424 - val_mae: 8.0424\n",
      "Epoch 52/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 236ms/step - loss: 5.0219 - mae: 5.0219 - val_loss: 8.0334 - val_mae: 8.0334\n",
      "Epoch 53/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 241ms/step - loss: 5.2136 - mae: 5.2136 - val_loss: 7.9488 - val_mae: 7.9488\n",
      "Epoch 54/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 242ms/step - loss: 6.6788 - mae: 6.6788 - val_loss: 7.8036 - val_mae: 7.8036\n",
      "Epoch 55/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 250ms/step - loss: 5.5395 - mae: 5.5395 - val_loss: 7.6262 - val_mae: 7.6262\n",
      "Epoch 56/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 253ms/step - loss: 6.0463 - mae: 6.0463 - val_loss: 7.5605 - val_mae: 7.5605\n",
      "Epoch 57/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 286ms/step - loss: 4.7002 - mae: 4.7002 - val_loss: 7.5023 - val_mae: 7.5023\n",
      "Epoch 58/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 321ms/step - loss: 4.9394 - mae: 4.9394 - val_loss: 7.4414 - val_mae: 7.4414\n",
      "Epoch 59/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309ms/step - loss: 4.6967 - mae: 4.6967 - val_loss: 7.4796 - val_mae: 7.4796\n",
      "Epoch 60/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298ms/step - loss: 4.9755 - mae: 4.9755 - val_loss: 7.5680 - val_mae: 7.5680\n",
      "Epoch 61/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304ms/step - loss: 5.5054 - mae: 5.5054 - val_loss: 7.6151 - val_mae: 7.6151\n",
      "Epoch 62/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304ms/step - loss: 5.1962 - mae: 5.1962 - val_loss: 7.6364 - val_mae: 7.6364\n",
      "Epoch 63/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329ms/step - loss: 5.1050 - mae: 5.1050 - val_loss: 7.5913 - val_mae: 7.5913\n",
      "Epoch 64/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 347ms/step - loss: 5.2195 - mae: 5.2195 - val_loss: 7.5132 - val_mae: 7.5132\n",
      "Epoch 65/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 351ms/step - loss: 5.6691 - mae: 5.6691 - val_loss: 7.4272 - val_mae: 7.4272\n",
      "Epoch 66/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 342ms/step - loss: 5.0230 - mae: 5.0230 - val_loss: 7.3150 - val_mae: 7.3150\n",
      "Epoch 67/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335ms/step - loss: 5.1579 - mae: 5.1579 - val_loss: 7.1491 - val_mae: 7.1491\n",
      "Epoch 68/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 325ms/step - loss: 5.2427 - mae: 5.2427 - val_loss: 7.1603 - val_mae: 7.1603\n",
      "Epoch 69/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 323ms/step - loss: 5.8315 - mae: 5.8315 - val_loss: 7.1728 - val_mae: 7.1728\n",
      "Epoch 70/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 330ms/step - loss: 5.3316 - mae: 5.3316 - val_loss: 7.3536 - val_mae: 7.3536\n",
      "Epoch 71/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335ms/step - loss: 5.9902 - mae: 5.9902 - val_loss: 7.4919 - val_mae: 7.4919\n",
      "Epoch 72/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 323ms/step - loss: 6.0621 - mae: 6.0621 - val_loss: 7.5541 - val_mae: 7.5541\n",
      "Epoch 73/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 321ms/step - loss: 5.3232 - mae: 5.3232 - val_loss: 7.5982 - val_mae: 7.5982\n",
      "Epoch 74/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327ms/step - loss: 6.3863 - mae: 6.3863 - val_loss: 7.4987 - val_mae: 7.4987\n",
      "Epoch 75/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 321ms/step - loss: 4.3972 - mae: 4.3972 - val_loss: 7.3091 - val_mae: 7.3091\n",
      "Epoch 76/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324ms/step - loss: 5.2090 - mae: 5.2090 - val_loss: 7.1298 - val_mae: 7.1298\n",
      "Epoch 77/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 328ms/step - loss: 5.4131 - mae: 5.4131 - val_loss: 7.0038 - val_mae: 7.0038\n",
      "Epoch 78/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320ms/step - loss: 5.2244 - mae: 5.2244 - val_loss: 6.9232 - val_mae: 6.9232\n",
      "Epoch 79/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 326ms/step - loss: 4.8178 - mae: 4.8178 - val_loss: 6.9022 - val_mae: 6.9022\n",
      "Epoch 80/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324ms/step - loss: 4.6672 - mae: 4.6672 - val_loss: 6.8813 - val_mae: 6.8813\n",
      "Epoch 81/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324ms/step - loss: 4.5788 - mae: 4.5788 - val_loss: 6.8523 - val_mae: 6.8523\n",
      "Epoch 82/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 329ms/step - loss: 5.6961 - mae: 5.6961 - val_loss: 6.8264 - val_mae: 6.8264\n",
      "Epoch 83/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 346ms/step - loss: 4.6236 - mae: 4.6236 - val_loss: 6.8070 - val_mae: 6.8070\n",
      "Epoch 84/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 340ms/step - loss: 3.9524 - mae: 3.9524 - val_loss: 6.7918 - val_mae: 6.7918\n",
      "Epoch 85/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 320ms/step - loss: 4.3913 - mae: 4.3913 - val_loss: 6.7797 - val_mae: 6.7797\n",
      "Epoch 86/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335ms/step - loss: 4.3650 - mae: 4.3650 - val_loss: 6.7623 - val_mae: 6.7623\n",
      "Epoch 87/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331ms/step - loss: 4.9393 - mae: 4.9393 - val_loss: 6.7482 - val_mae: 6.7482\n",
      "Epoch 88/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 315ms/step - loss: 3.9074 - mae: 3.9074 - val_loss: 6.7417 - val_mae: 6.7417\n",
      "Epoch 89/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 325ms/step - loss: 5.7965 - mae: 5.7965 - val_loss: 6.7830 - val_mae: 6.7830\n",
      "Epoch 90/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 313ms/step - loss: 4.7242 - mae: 4.7242 - val_loss: 6.8418 - val_mae: 6.8418\n",
      "Epoch 91/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 325ms/step - loss: 4.5641 - mae: 4.5641 - val_loss: 6.8978 - val_mae: 6.8978\n",
      "Epoch 92/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 327ms/step - loss: 4.7754 - mae: 4.7754 - val_loss: 6.9075 - val_mae: 6.9075\n",
      "Epoch 93/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 324ms/step - loss: 4.7798 - mae: 4.7798 - val_loss: 6.9340 - val_mae: 6.9340\n",
      "Epoch 94/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 323ms/step - loss: 4.2379 - mae: 4.2379 - val_loss: 6.9422 - val_mae: 6.9422\n",
      "Epoch 95/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335ms/step - loss: 5.6238 - mae: 5.6238 - val_loss: 6.9170 - val_mae: 6.9170\n",
      "Epoch 96/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 351ms/step - loss: 4.4051 - mae: 4.4051 - val_loss: 6.8530 - val_mae: 6.8530\n",
      "Epoch 97/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 325ms/step - loss: 4.7306 - mae: 4.7306 - val_loss: 6.7585 - val_mae: 6.7585\n",
      "Epoch 98/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331ms/step - loss: 3.8926 - mae: 3.8926 - val_loss: 6.6534 - val_mae: 6.6534\n",
      "Epoch 99/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 341ms/step - loss: 4.3288 - mae: 4.3288 - val_loss: 6.6012 - val_mae: 6.6012\n",
      "Epoch 100/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 331ms/step - loss: 3.9241 - mae: 3.9241 - val_loss: 6.5811 - val_mae: 6.5811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé sous 'age_estimation_model.h5'\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T08:47:53.909534Z",
     "start_time": "2025-01-22T08:47:52.371200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Charger le modèle sauvegardé\n",
    "model = load_model(\"age_estimation_model.h5\")\n",
    "\n",
    "# Fonction pour tester avec une image\n",
    "def predict_age(image_path):\n",
    "    # Charger l'image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Erreur : Impossible de charger l'image {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Prétraiter l'image (redimensionner et normaliser)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img / 255.0  # Normalisation\n",
    "    img = np.expand_dims(img, axis=0)  # Ajouter une dimension pour le batch\n",
    "    \n",
    "    # Effectuer la prédiction\n",
    "    predicted_age = model.predict(img)[0][0]  # Prédiction (régression)\n",
    "    \n",
    "    # Afficher le résultat\n",
    "    print(f\"Âge estimé : {predicted_age:.2f} ans\")\n",
    "\n",
    "# Tester avec une image\n",
    "predict_age(r\"C:\\Users\\33658\\Downloads\\cruise50.png\")\n"
   ],
   "id": "d41db8df60e843b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 643ms/step\n",
      "Âge estimé : 32.63 ans\n"
     ]
    }
   ],
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
