{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-23T07:59:25.679912Z",
     "start_time": "2025-01-23T07:58:15.053024Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.src.utils.module_utils import tensorflow\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Charger les données depuis un fichier CSV\n",
    "data = pd.read_csv(r\"C:\\Users\\33658\\PycharmProjects\\Act-O-Matic\\Datasets\\IMDB Scrap Cropped\\Natalie Portman Crop\\index_cleaned.csv\", delimiter=\";\")\n",
    "\n",
    "# Charger et prétraiter les images\n",
    "def preprocess_data(data):\n",
    "    images, ages = [], []\n",
    "    base_path = r\"C:\\Users\\33658\\PycharmProjects\\Act-O-Matic\\Datasets\\IMDB Scrap Cropped\\Natalie Portman Crop\"\n",
    "    for i, row in data.iterrows():\n",
    "        img_name = str(row[\"Image\"]) + \"_face\"+ \".jpg\" \n",
    "        img_path = os.path.join(base_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Image non trouvée : {img_path}\")\n",
    "            continue\n",
    "        img = cv2.resize(img, (224, 224))   # Redimensionner\n",
    "        img = img / 255.0                   # Normaliser\n",
    "        images.append(img)\n",
    "        ages.append(float(row[\"Age\"]))\n",
    "    return np.array(images), np.array(ages)\n",
    "\n",
    "# Prétraiter les données\n",
    "images, ages = preprocess_data(data)\n",
    "\n",
    "# Diviser en ensembles d'entraînement et de validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(images, ages, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir en tenseurs\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32).shuffle(1000)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(32)\n",
    "\n",
    "# Charger le modèle pré-entraîné MobileNetV2\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Ajouter des couches personnalisées\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(1, activation='linear')(x)  # Activation linéaire pour une régression\n",
    "\n",
    "# Construire le modèle\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Geler les couches du modèle pré-entraîné\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"mean_absolute_error\",  # Erreur absolue moyenne pour la régression\n",
    "    metrics=[\"mae\"]  # Suivi de la MAE\n",
    ")\n",
    "\n",
    "# Ajouter un callback pour l'early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "model.save(\"age_estimation_model_Nat.h5\")\n",
    "model.save(\"../Models/age_estimation_model_Nat.keras\")\n",
    "print(\"Modèle sauvegardé sous 'age_estimation_model_Nat.h5'\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 397ms/step - loss: 23.6520 - mae: 23.6520 - val_loss: 11.0678 - val_mae: 11.0678\n",
      "Epoch 2/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 214ms/step - loss: 9.1877 - mae: 9.1877 - val_loss: 8.0121 - val_mae: 8.0121\n",
      "Epoch 3/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 359ms/step - loss: 8.6109 - mae: 8.6109 - val_loss: 8.4207 - val_mae: 8.4207\n",
      "Epoch 4/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 540ms/step - loss: 8.4269 - mae: 8.4269 - val_loss: 7.0360 - val_mae: 7.0360\n",
      "Epoch 5/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 438ms/step - loss: 6.7240 - mae: 6.7240 - val_loss: 8.1786 - val_mae: 8.1786\n",
      "Epoch 6/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 409ms/step - loss: 7.3862 - mae: 7.3862 - val_loss: 7.3055 - val_mae: 7.3055\n",
      "Epoch 7/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 453ms/step - loss: 6.9125 - mae: 6.9125 - val_loss: 6.7081 - val_mae: 6.7081\n",
      "Epoch 8/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 575ms/step - loss: 7.2463 - mae: 7.2463 - val_loss: 6.6402 - val_mae: 6.6402\n",
      "Epoch 9/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 409ms/step - loss: 5.8268 - mae: 5.8268 - val_loss: 6.6068 - val_mae: 6.6068\n",
      "Epoch 10/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 397ms/step - loss: 6.5122 - mae: 6.5122 - val_loss: 6.5636 - val_mae: 6.5636\n",
      "Epoch 11/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 401ms/step - loss: 6.2907 - mae: 6.2907 - val_loss: 6.5017 - val_mae: 6.5017\n",
      "Epoch 12/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 447ms/step - loss: 5.8038 - mae: 5.8038 - val_loss: 6.4373 - val_mae: 6.4373\n",
      "Epoch 13/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 402ms/step - loss: 5.9210 - mae: 5.9210 - val_loss: 6.4031 - val_mae: 6.4031\n",
      "Epoch 14/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 397ms/step - loss: 5.4001 - mae: 5.4001 - val_loss: 6.5095 - val_mae: 6.5095\n",
      "Epoch 15/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 451ms/step - loss: 4.9423 - mae: 4.9423 - val_loss: 6.3096 - val_mae: 6.3096\n",
      "Epoch 16/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 445ms/step - loss: 4.9755 - mae: 4.9755 - val_loss: 6.2865 - val_mae: 6.2865\n",
      "Epoch 17/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 379ms/step - loss: 5.1788 - mae: 5.1788 - val_loss: 6.4078 - val_mae: 6.4078\n",
      "Epoch 18/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 383ms/step - loss: 5.4187 - mae: 5.4187 - val_loss: 6.3060 - val_mae: 6.3060\n",
      "Epoch 19/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 396ms/step - loss: 5.1180 - mae: 5.1180 - val_loss: 6.2092 - val_mae: 6.2092\n",
      "Epoch 20/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 394ms/step - loss: 5.4781 - mae: 5.4781 - val_loss: 6.2027 - val_mae: 6.2027\n",
      "Epoch 21/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 428ms/step - loss: 5.1911 - mae: 5.1911 - val_loss: 6.2109 - val_mae: 6.2109\n",
      "Epoch 22/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 377ms/step - loss: 5.1458 - mae: 5.1458 - val_loss: 6.4025 - val_mae: 6.4025\n",
      "Epoch 23/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 400ms/step - loss: 5.1736 - mae: 5.1736 - val_loss: 6.5140 - val_mae: 6.5140\n",
      "Epoch 24/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 414ms/step - loss: 5.3083 - mae: 5.3083 - val_loss: 6.5194 - val_mae: 6.5194\n",
      "Epoch 25/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 380ms/step - loss: 4.9203 - mae: 4.9203 - val_loss: 6.3506 - val_mae: 6.3506\n",
      "Epoch 26/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 383ms/step - loss: 4.9911 - mae: 4.9911 - val_loss: 6.3473 - val_mae: 6.3473\n",
      "Epoch 27/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 458ms/step - loss: 5.0983 - mae: 5.0983 - val_loss: 6.2291 - val_mae: 6.2291\n",
      "Epoch 28/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 447ms/step - loss: 5.0993 - mae: 5.0993 - val_loss: 6.2515 - val_mae: 6.2515\n",
      "Epoch 29/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 764ms/step - loss: 5.3847 - mae: 5.3847 - val_loss: 6.7212 - val_mae: 6.7212\n",
      "Epoch 30/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1s/step - loss: 4.8584 - mae: 4.8584 - val_loss: 6.3387 - val_mae: 6.3387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé sous 'age_estimation_model_Nat.h5'\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T07:55:12.652638Z",
     "start_time": "2025-01-23T07:55:12.638004Z"
    }
   },
   "cell_type": "code",
   "source": "tf.keras.saving.save_model(model, 'age_estimation_model_cruise.keras')",
   "id": "a7d465e43f26d605",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras' has no attribute 'saving'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msaving\u001B[49m\u001B[38;5;241m.\u001B[39msave_model(model, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage_estimation_model_Tom.keras\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tensorflow.keras' has no attribute 'saving'"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T07:55:40.690011Z",
     "start_time": "2025-01-23T07:55:39.084005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Charger le modèle sauvegardé\n",
    "model = load_model(\"age_estimation_model_cruise.h5\")\n",
    "\n",
    "# Fonction pour tester avec une image\n",
    "def predict_age(image_path):\n",
    "    # Charger l'image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Erreur : Impossible de charger l'image {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Prétraiter l'image (redimensionner et normaliser)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img / 255.0  # Normalisation\n",
    "    img = np.expand_dims(img, axis=0)  # Ajouter une dimension pour le batch\n",
    "    \n",
    "    # Effectuer la prédiction\n",
    "    predicted_age = model.predict(img)[0][0]  # Prédiction (régression)\n",
    "    \n",
    "    # Afficher le résultat\n",
    "    print(f\"Âge estimé : {predicted_age:.2f} ans\")\n",
    "\n",
    "# Tester avec une image\n",
    "predict_age(r\"C:\\Users\\33658\\Downloads\\braff1.jpg\")\n"
   ],
   "id": "d41db8df60e843b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1s/step\n",
      "Âge estimé : 30.66 ans\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
